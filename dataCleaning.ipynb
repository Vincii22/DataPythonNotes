{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e87709",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales.csv')\n",
    "sales.head(2)\n",
    "\n",
    "#get the datatype of columns\n",
    "\n",
    "sales.dtypes\n",
    "\n",
    "#get dataframe information\n",
    "sales.info()\n",
    "\n",
    "\n",
    "#Print sum of all revenue column\n",
    "sales['Revenue'].sum()\n",
    "\n",
    "sales['Revenue'] = sales['Revenue'].str.strip('$')\n",
    "sales['Revenue'] = sales['Revenue'].astype('int')\n",
    "\n",
    "#Assert is one way to verify something (like if) if it is True then it returns nothing\n",
    "\n",
    "assert 1+1 == 2\n",
    "\n",
    "#Otherwise (False) it returns an error\n",
    "assert 1+1 == 3\n",
    "assert sales['Revenue'].dtype == 'int'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3cf5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical or Categorical?\n",
    "\n",
    "df['marriage_status'].describe()\n",
    "\n",
    "#Convert to categorical\n",
    "\n",
    "df['marriage_status'] = df['marriage_status'].astype('category')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbeca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "\n",
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print the information of ride_sharing\n",
    "print(ride_sharing.info())\n",
    "\n",
    "# Print summary statistics of user_type column\n",
    "print(ride_sharing['user_type'].describe())\n",
    "\n",
    "# Convert user_type from integer to category\n",
    "ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')\n",
    "\n",
    "# Write an assert statement confirming the change\n",
    "assert ride_sharing['user_type_cat'].dtype == 'category'\n",
    "\n",
    "# Print new summary statistics \n",
    "print(ride_sharing['user_type_cat'].describe())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "\n",
    "# Strip duration of minutes\n",
    "ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes')\n",
    "\n",
    "# Convert duration to integer\n",
    "ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')\n",
    "\n",
    "# Write an assert statement making sure of conversion\n",
    "assert ride_sharing['duration_time'].dtype == 'int'\n",
    "\n",
    "# Print formed columns and calculate average ride duration \n",
    "print(ride_sharing[['duration','duration_trim','duration_time']])\n",
    "print(ride_sharing['duration_time'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc25f1",
   "metadata": {},
   "source": [
    "Data Range Constraints\n",
    "\n",
    "Motivation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(movies['avg_rating'])\n",
    "plt.title('Average rating of movies (1-5)')\n",
    "\n",
    "\n",
    "How to deal with out of range data?\n",
    "\n",
    "- Dropping Data\n",
    "- Setting custom minimums and maximums\n",
    "- Treat as missing and impute\n",
    "- Setting custom value depending on business assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d61768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "# Output movies with rating > 5\n",
    "movies[movies['avg_rating'] > 5]\n",
    "\n",
    "#Drop values using filtering example\n",
    "\n",
    "movies = movies[movies['avg_rating'] <= 5]\n",
    "\n",
    "movies.drop(movies[movies['avg_rating'] > 5].index, inplace = True)\n",
    "\n",
    "# Convert avg_rating > 5 to 5\n",
    "movies.loc[movies['avg_rating'] > 5, 'avg_rating'] = 5\n",
    "\n",
    "assert movies['avg_rating'].max() <= 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2601f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data range examples\n",
    "\n",
    "import datetime as dt\n",
    "today_date = dt.date.today()\n",
    "user_signups[user_signups['subscribtion_date'] > dt.date.today()]\n",
    "\n",
    "import datetime as dt \n",
    "import pandas as pd\n",
    "\n",
    "#Outputs data types\n",
    "user_signups.dtypes\n",
    "\n",
    "#Convert to date\n",
    "\n",
    "user_signups['subscription_date'] = pd.to_datetime(user_signups['subscription_date']).dt.date\n",
    "\n",
    "\n",
    "today_date = dt.date.today()\n",
    "\n",
    "# Drop Data \n",
    "\n",
    "#Drop values using filtering\n",
    "user_signups = user_signups[user_signups['subscription_date'] < today_date]\n",
    "#Drop values using .drop()\n",
    "user_signups.drop(user_signups[user_signups['subscription_date'] > today_date].index, inplace = True)\n",
    "\n",
    "\n",
    "#Hardcode dates with upper limit\n",
    "\n",
    "user_signups.loc[user_signups['subscription_date'] > today_date, 'subscription_date'] = today_date \n",
    "assert user_signups.subscription_date.max().date() <= today_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "\n",
    "# Convert tire_sizes to integer\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')\n",
    "\n",
    "# Set all values above 27 to 27\n",
    "ride_sharing.loc[ride_sharing['tire_sizes'] > 27, 'tire_sizes'] = 27\n",
    "\n",
    "# Reconvert tire_sizes back to categorical\n",
    "ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')\n",
    "\n",
    "# Print tire size description\n",
    "print(ride_sharing['tire_sizes'].describe())\n",
    "\n",
    "\n",
    "# Convert ride_date to date\n",
    "ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date']).dt.date\n",
    "\n",
    "# Save today's date\n",
    "today = dt.date.today()\n",
    "\n",
    "# Set all in the future to today's date\n",
    "ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today\n",
    "\n",
    "# Print maximum of ride_dt column\n",
    "print(ride_sharing['ride_dt'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3359a",
   "metadata": {},
   "source": [
    "Uniqueness Constraints\n",
    "\n",
    "Duplicate Values\n",
    "\n",
    "- Most columns have the same values\n",
    "\n",
    "Why do they happen?\n",
    "\n",
    "- Data Entry & Human Error\n",
    "- Bugs and design error\n",
    "- Join or merge errors\n",
    "\n",
    "How to find duplicate rows?\n",
    "\n",
    "- The .duplicated() method\n",
    "- subset: List of columns names to check for duplication\n",
    "- keep: Whether to keep first('first'), last('last'), or all (False) duplicate values\n",
    "\n",
    "- .sort_values\n",
    "\n",
    "\n",
    "How to treat duplicated values?\n",
    "\n",
    "- The .drop_duplicates method\n",
    "- subset: List of columns to check for duplication\n",
    "- keep: Whether to keep first('first'), last('last'), or all (False) duplicate values\n",
    "- inplace: Drop duplicated rows directly inside DataFrame without creating new object (True).\n",
    "\n",
    "- The .groupby() and agg() methods\n",
    "- .reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_weight.head()\n",
    "\n",
    "# Get duplicates across columns\n",
    "\n",
    "duplicates = height_weight.duplicated() #Duplicated Keyword (Method)\n",
    "print(duplicates)\n",
    "\n",
    "# Get duplicate rows\n",
    "\n",
    "height_weight[duplicates]\n",
    "\n",
    "\n",
    "\n",
    "#Column names to check for duplication\n",
    "\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "\n",
    "height_weight[duplicates]\n",
    "\n",
    "#Output duplicated values\n",
    "height_weight[duplicates].sort_values(by = 'first_name')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f37356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hoow to treat duplicated values\n",
    "\n",
    "#Drop duplicates\n",
    "\n",
    "height_weight.drop_duplicates(inplace = True)\n",
    "\n",
    "#Output duplicated values\n",
    "\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "height_weight[duplicates],sort_values(by = 'first_name')\n",
    "\n",
    "\n",
    "# Group by colum names and produce statistical summaries\n",
    "\n",
    "column_names = ['first_name', 'last_name', 'address']\n",
    "summaries = {'height': 'max', 'weight': 'mean'}\n",
    "height_weight = height_weight.groupby(by = column_names).agg(summaries).reset_index()\n",
    "\n",
    "# Make sure the aggregation is done\n",
    "\n",
    "duplicates = height_weight.duplicated(subset = column_names, keep = False)\n",
    "height_weight[duplicates].sort_values(by = 'first_name')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "\n",
    "# Find duplicated rows of ride_id in the ride_sharing DataFrame while setting keep to False.\n",
    "# Subset ride_sharing on duplicates and sort by ride_id and assign the results to duplicated_rides.\n",
    "# Print the ride_id, duration and user_birth_year columns of duplicated_rides in that order\n",
    "\n",
    "# Find duplicates\n",
    "duplicates = ride_sharing.duplicated(subset = 'ride_id', keep = False)\n",
    "\n",
    "# Sort your duplicated rides\n",
    "duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')\n",
    "\n",
    "# Print relevant columns of duplicated_rides\n",
    "print(duplicated_rides[['ride_id','duration','user_birth_year']])\n",
    "\n",
    "\n",
    "#Instruction\n",
    "\n",
    "# Drop complete duplicates in ride_sharing and store the results in ride_dup.\n",
    "# Create the statistics dictionary which holds minimum aggregation for user_birth_year and mean aggregation for duration.\n",
    "# Drop incomplete duplicates by grouping by ride_id and applying the aggregation in statistics.\n",
    "# Find duplicates again and run the assert statement to verify de-duplication.\n",
    "\n",
    "\n",
    "# Drop complete duplicates from ride_sharing\n",
    "ride_dup = ride_sharing.drop_duplicates()\n",
    "\n",
    "# Create statistics dictionary for aggregation function\n",
    "statistics = {'user_birth_year': 'min', 'duration': 'mean'}\n",
    "\n",
    "# Group by ride_id and compute new statistics\n",
    "ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()\n",
    "\n",
    "# Find duplicated values again\n",
    "duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)\n",
    "duplicated_rides = ride_unique[duplicates == True]\n",
    "\n",
    "# Assert duplicates are processed\n",
    "assert duplicated_rides.shape[0] == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e4064",
   "metadata": {},
   "source": [
    "Membership Constraints\n",
    "\n",
    "Categories and Membership Constraints\n",
    "\n",
    "Predefined finite sets of categories\n",
    "\n",
    "Type of Data                    Example Values              Numeric Representation\n",
    "\n",
    "Marriage Status                 unmarried, married              0,1\n",
    "Household income category       0-20k, 20-40k                   0,1, ...\n",
    "Loand Status                    default, paid, no_loan          0, 1, 2\n",
    "\n",
    "\n",
    "Why could we have these problems?\n",
    "\n",
    "- Data Entry Errors\n",
    "- Parsing Errors\n",
    "\n",
    "How do we treat these problems?\n",
    "\n",
    "- Dropping data\n",
    "- Remapping categories\n",
    "- Inferring categories\n",
    "\n",
    "- categories\n",
    "- Methods:\n",
    "- Using set()\n",
    "- difference()\n",
    "- isin()\n",
    "\n",
    "- ~ (negate)\n",
    "A note on Joins\n",
    "\n",
    "Anti Joins                                      Inner Joins\n",
    "\n",
    "A   B                                            A       B\n",
    "\n",
    "What is in A and not in B                    What is in both A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc19d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read study data and print it \n",
    "\n",
    "study_data = pd.read_csv('study.csv')\n",
    "study_data\n",
    "\n",
    "#correct possible blood_types\n",
    "\n",
    "categories\n",
    "\n",
    "#Finding inconsistent categories\n",
    "\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "print(inconsistent_categories)\n",
    "\n",
    "#Get and print rows with inconsistent categories\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "study_data[inconsistent_rows]\n",
    "\n",
    "\n",
    "#Dropping inconsistent categories\n",
    "\n",
    "inconsistent_categories = set(study_data['blood_type']).difference(categories['blood_type'])\n",
    "inconsistent_rows = study_data['blood_type'].isin(inconsistent_categories)\n",
    "inconsistent_data = study_data[inconsistent_rows]\n",
    "\n",
    "# Drop inconsistent categories and get consistent data only\n",
    "consistent_data = study_data[~inconsistent_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "\n",
    "# Print categories DataFrame\n",
    "print(categories)\n",
    "\n",
    "# Print unique values of survey columns in airlines\n",
    "print('Cleanliness: ', airlines['cleanliness'].unique(), \"\\n\")\n",
    "print('Safety: ', airlines['safety'].unique(), \"\\n\")\n",
    "print('Satisfaction: ', airlines['satisfaction'].unique(), \"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "\n",
    "#Instructions:\n",
    "\n",
    "# Create a set out of the cleanliness column in airlines using set() and find the inconsistent category by finding the difference in the cleanliness column of categories.\n",
    "# Find rows of airlines with a cleanliness value not in categories and print the output.\n",
    "\n",
    "# Find the cleanliness category in airlines not in categories\n",
    "cat_clean = set(airlines['cleanliness']).difference(categories['cleanliness'])\n",
    "\n",
    "# Find rows with that category\n",
    "cat_clean_rows = airlines['cleanliness'].isin(cat_clean)\n",
    "\n",
    "# Print rows with inconsistent category\n",
    "print(airlines[cat_clean_rows])\n",
    "\n",
    "# Print rows with consistent categories only\n",
    "print(airlines[~cat_clean_rows])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5eaa3c",
   "metadata": {},
   "source": [
    "Categorical Variables\n",
    "\n",
    "What type of errors could we have?\n",
    "\n",
    "- Value inconsistency\n",
    "    - Inconsistent fields: 'married', 'Maried', 'UNMARRIED', 'not married'..\n",
    "    - _Trailing white spaces:_'married', ' married '...\n",
    "- Collapsing too many categories to few\n",
    "    - Creating new groups: 0-20K, 20-40K categories..from continuous household income data\n",
    "    - Mapping groups to new ones: Mapping household income categories to 2 'rich', 'poor'\n",
    "- Making sure data is of type category(seen in chapter 1)\n",
    "\n",
    "\n",
    "Value Consistency\n",
    "\n",
    "- Capitalization: 'married', 'Maried', 'UNMARRIED', 'not married'.. \n",
    "\n",
    "- Methods:\n",
    "- demographics[]\n",
    "- value_counts()\n",
    "- str_upper() - to Capitalize\n",
    "- str_lower() - to lowercase\n",
    "- str_strip() - to remove whitespaces\n",
    "\n",
    "Collapsing data into categories\n",
    "\n",
    "- Methods:\n",
    "- qcut() \n",
    "    - q, labels\n",
    "- cut()\n",
    "    - bins - ranges, labels - name, np.inf\n",
    "\n",
    "- Map categories to fewer ones: reducing categories in categorical column\n",
    "    - operating_system column is: 'Microsoft', 'MacOS', 'IOS', 'Android', 'Linux'\n",
    "    - operating_system column should become: 'DesktopOS', 'MobileOS'\n",
    "- Methods:\n",
    "- replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775edbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09feb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value Consistency\n",
    "#Get marriage status column\n",
    "marriage_status = demographics['marriage_status']\n",
    "marriage_status.value_counts()\n",
    "\n",
    "#get value counts on DataFrame\n",
    "marriage_status.groupby('marriage_status').count()\n",
    "\n",
    "#Capitalize\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str_upper()\n",
    "marriage_status['marriage_status'].value_counts()\n",
    "\n",
    "#Lowercase\n",
    "marriage_status['marriage_status'] = marriage_status['marriage_status'].str_lower()\n",
    "marriage_status['marriage_status'].value_counts()\n",
    "\n",
    "# Get marriage status column\n",
    "marriage_status = demographics['marriage_status']\n",
    "marriage_status.value_counts()\n",
    "\n",
    "\n",
    "#Strip all spaces\n",
    "demographics = demographics['marriage_status'].str_strip()\n",
    "demographics[marriage_status].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd352cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapsing data into categories\n",
    "#Using qcut\n",
    "import pandas as pd\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "demographics[income_group] = pd.qcut(demographics['household_income'], q = 3, labels = group_names)\n",
    "\n",
    "#Print income_group column\n",
    "demographics[['income_group', 'household_income']]\n",
    "\n",
    "\n",
    "#Using cut()\n",
    "ranges = [0, 20000, 50000, np.inf]\n",
    "group_names = ['0-200K', '200K-500K', '500K+']\n",
    "\n",
    "#Create income group column\n",
    "demographics['income_group'] = pd.cut(demographics['household_income'], bins = ranges, labels = group_names)\n",
    "demographics[['income_group', 'household_income']]\n",
    "\n",
    "\n",
    "# - Map categories to fewer ones: reducing categories in categorical column\n",
    "\n",
    "mapping = {'Microsoft': 'DesktopOS', 'MacOS': 'DesktopOS', 'Linux': 'DesktopOS', 'IOS': 'MobileOS', 'Android': 'MobileOS'}\n",
    "devices['operating_system'] = devices['operating_system'].replace(mapping)\n",
    "devices['operating_system'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercises\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "\n",
    "# Print unique values of both columns\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# Lower dest_region column and then replace \"eur\" with \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower() \n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# Remove white spaces from `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# Verify changes have been effected\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "\n",
    "#Instructions\n",
    "\n",
    "# Create the ranges and labels for the wait_type column mentioned in the description.\n",
    "# Create the wait_type column by from wait_min by using pd.cut(), while inputting label_ranges and label_names in the correct arguments.\n",
    "# Create the mapping dictionary mapping weekdays to 'weekday' and weekend days to 'weekend'.\n",
    "# Create the day_week column by using .replace().\n",
    "\n",
    "# Create ranges for categories\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# Create wait_type column\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, \n",
    "                                labels = label_names)\n",
    "\n",
    "# Create mappings and replace\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983efadb",
   "metadata": {},
   "source": [
    "Cleaning Text Data\n",
    "\n",
    "What is Text Data?\n",
    "\n",
    "Type of Data                Example Values\n",
    "Names                       Alex, Sara,...\n",
    "Phone Numbers               +96171679912 ...\n",
    "Emails                      `adel@datacamp.com`\n",
    "Passwords                   ...\n",
    "\n",
    "Common text data problems:\n",
    "\n",
    "- Data Inconsistency:\n",
    "    - +96171679912 or 0096171679912 or ..?\n",
    "- Fixed Lengths violations:\n",
    "    - Password needs to be atleast 8 characters\n",
    "- Typos:\n",
    "    - +961.71.679912"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abefdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
